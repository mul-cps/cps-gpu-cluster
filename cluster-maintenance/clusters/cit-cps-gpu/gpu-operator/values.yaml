# NVIDIA GPU Operator Configuration for Ubuntu 24.04

# Driver configuration
driver:
  enabled: true
  repository: nvcr.io/nvidia
  image: driver
  version: "580.95.05"
  # Disable precompiled to use generic Ubuntu 24.04 driver
  usePrecompiled: false
  # Use auto kernel module type
  kernelModuleType: "auto"

# NVIDIA Container Toolkit - K3s configuration
toolkit:
  enabled: true
  version: "v1.18.0"
  env:
    - name: CONTAINERD_CONFIG
      value: /var/lib/rancher/k3s/agent/etc/containerd/config.toml
    - name: CONTAINERD_SOCKET
      value: /run/k3s/containerd/containerd.sock
    - name: CONTAINERD_RUNTIME_CLASS
      value: nvidia
    - name: CONTAINERD_SET_AS_DEFAULT
      value: "true"

# Device Plugin
devicePlugin:
  enabled: true
  version: "v0.18.0"

# DCGM Exporter (GPU metrics)
dcgmExporter:
  enabled: true
  version: "4.4.1-4.6.0-distroless"

# GPU Feature Discovery
gfd:
  enabled: true
  version: "v0.18.0"

# MIG Manager (for A100 MIG partitioning - enabled by default in v25.10.0)
migManager:
  enabled: true

# Node Feature Discovery
nfd:
  enabled: true

# Operator configuration
operator:
  defaultRuntime: containerd
  initContainer:
    image: cuda
    repository: nvcr.io/nvidia
    version: 13.0.1-base-ubi9

# Tolerations for control plane if needed
tolerations: []
  # - key: "node-role.kubernetes.io/control-plane"
  #   operator: "Exists"
  #   effect: "NoSchedule"

# Node selector - deploy only to GPU nodes
nodeSelector:
  accelerator: nvidia
