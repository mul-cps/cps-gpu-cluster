apiVersion: v1
kind: Pod
metadata:
  name: gpu-stress-test
  namespace: default
spec:
  restartPolicy: Never
  containers:
  - name: gpu-stress
    image: nvcr.io/nvidia/pytorch:22.12-py3
    command: ["/bin/bash", "-c"]
    args: 
    - |
      echo "Starting GPU stress test..."
      python3 -c "
      import torch
      import time
      device = torch.cuda.current_device()
      print(f'Using GPU: {torch.cuda.get_device_name(device)}')
      # Create tensors to use GPU memory and compute
      for i in range(10):
          print(f'Iteration {i+1}/10')
          x = torch.randn(5000, 5000, device='cuda')
          y = torch.randn(5000, 5000, device='cuda')
          # Matrix multiplication to stress GPU
          z = torch.matmul(x, y)
          # Tensor operations to use tensor cores
          z = torch.matmul(z.half(), z.half())
          time.sleep(5)
      print('GPU stress test completed')
      "
    resources:
      requests:
        nvidia.com/gpu: 1
      limits:
        nvidia.com/gpu: 1
