# =============================================================================
# JupyterHub Configuration (modular)
# - Storage/Ingress/DB: as before
# - UI/Profiles/Culler moved to hub.extraFiles + tiny loaders
# - MIG limited to 1g.5gb
# =============================================================================

proxy:
  service:
    type: ClusterIP
  chp:
    extraEnv:
      CONFIGPROXY_NUM_WORKERS: "6"

ingress:
  enabled: true
  ingressClassName: nginx
  hosts: [jupyterhub.cps.unileoben.ac.at]
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/enable-websocket: "true"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-body-size: "2g"
    nginx.ingress.kubernetes.io/proxy-buffering: "on"
    nginx.ingress.kubernetes.io/proxy-buffers-number: "16"
    nginx.ingress.kubernetes.io/proxy-buffer-size: "32k"
    nginx.ingress.kubernetes.io/proxy-next-upstream: "error timeout http_502 http_503 http_504"
    nginx.ingress.kubernetes.io/proxy-next-upstream-tries: "3"
  tls:
    - secretName: jupyterhub-tls
      hosts: [jupyterhub.cps.unileoben.ac.at]

hub:
  config:
    JupyterHub:
      admin_access: true
      authenticator_class: oauthenticator.generic.GenericOAuthenticator
      allow_named_servers: true
      named_server_limit_per_user: 3
      template_vars:
        org:
          name: "MontanuniversitÃ¤t Leoben"
          logo_url: "https://www.unileoben.ac.at/fileadmin/shares/allgemeine_datenbank/logos/1-mul-logo/2-mul-logo-smoke-quer.svg"
          url: "https://www.unileoben.ac.at"

    GenericOAuthenticator:
      # OAuth configuration will be loaded from auth.py module
      manage_groups: true
      admin_groups: ["jupyter_admin", "cpsHPCAccess"]

  # PostgreSQL (no sqlite)
  db:
    type: postgres
    url: postgresql://jhub:jhub-secure-db-password-2025@postgresql.jupyterhub.svc.cluster.local:5432/jhub

  # Hub sizing for 200+ concurrent users
  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "2"
      memory: "4Gi"
  extraEnv:
    JUPYTERHUB_API_PAGE_SIZE: "200"
    JUPYTERHUB_ACTIVE_SERVER_LIMIT: "0"

  extraVolumes:
    - name: custom-templates
      configMap:
        name: jupyterhub-custom-templates
  extraVolumeMounts:
    - name: custom-templates
      mountPath: /etc/jupyterhub/custom

  # ---------- Ship modular files into the Hub ----------
  extraFiles:
    # UI Configuration
    ui_options_form:
      mountPath: /etc/jupyterhub/extra/ui_options_form.html
      stringData: |
{{ .Files.Get "config/ui_options_form.html" | indent 8 }}
    
    # Profile Configuration  
    profiles:
      mountPath: /etc/jupyterhub/extra/profiles.py
      stringData: |
{{ .Files.Get "config/profiles.py" | indent 8 }}
    
    # Culler Configuration
    culler_config:
      mountPath: /etc/jupyterhub/extra/culler.py  
      stringData: |
{{ .Files.Get "config/culler.py" | indent 8 }}
          
    # Auth Configuration
    auth_config:
      mountPath: /etc/jupyterhub/extra/auth.py
      stringData: |
{{ .Files.Get "config/auth.py" | indent 8 }}

  extraConfig:
    00-install-oauthenticator: |
      import subprocess, sys
      try:
          import oauthenticator  # noqa
      except ImportError:
          subprocess.check_call([sys.executable, "-m", "pip", "install", "oauthenticator"])

    00-auth-config: |
      # Load authentication configuration from modular file
      import importlib.util, sys
      spec = importlib.util.spec_from_file_location("auth", "/etc/jupyterhub/extra/auth.py")
      auth_mod = importlib.util.module_from_spec(spec)
      sys.modules["auth"] = auth_mod
      spec.loader.exec_module(auth_mod)
      
      # Apply OAuth configuration
      oauth_config = auth_mod.get_oauth_config()
      c.GenericOAuthenticator.client_id = oauth_config['client_id']
      c.GenericOAuthenticator.client_secret = oauth_config['client_secret']
      c.GenericOAuthenticator.oauth_callback_url = oauth_config['oauth_callback_url']
      c.GenericOAuthenticator.authorize_url = oauth_config['authorize_url']
      c.GenericOAuthenticator.token_url = oauth_config['token_url']
      c.GenericOAuthenticator.userdata_url = oauth_config['userdata_url']
      c.GenericOAuthenticator.login_service = oauth_config['login_service']
      c.GenericOAuthenticator.username_claim = oauth_config['username_claim']
      c.GenericOAuthenticator.userdata_params = oauth_config['userdata_params']
      c.GenericOAuthenticator.scope = oauth_config['scope']
      c.GenericOAuthenticator.claim_groups_key = oauth_config['claim_groups_key']
      
      # Apply admin configuration  
      admin_config = auth_mod.get_admin_config()
      c.Authenticator.admin_users = set(admin_config['users'])

    01-templates-and-info: |
      c.JupyterHub.template_paths = ['/etc/jupyterhub/custom']
      from jupyterhub.handlers import BaseHandler
      from tornado import web
      class InfoHandler(BaseHandler):
          @web.authenticated
          async def get(self):
              user = await self.get_current_user()
              jinja_env = self.settings.get('jinja2_env', None)
              template_vars = jinja_env.globals.get('template_vars', {}) if jinja_env else {}
              org = template_vars.get('org', {})
              html = self.render_template("info.html", user=user, base_url=self.base_url, org=org)
              self.write(html)
      c.JupyterHub.extra_handlers = [(r"/info", InfoHandler)]

    02-ui-options-form: |
      # Load the HTML UI from file
      with open('/etc/jupyterhub/extra/ui_options_form.html', 'r', encoding='utf-8') as f:
          c.Spawner.options_form = f.read()

    03-profiles: |
      # Wire up profile list + form parser + pre_spawn_hook
      import importlib.util, sys
      spec = importlib.util.spec_from_file_location("profiles", "/etc/jupyterhub/extra/profiles.py")
      mod = importlib.util.module_from_spec(spec); sys.modules["profiles"] = mod; spec.loader.exec_module(mod)
      c.KubeSpawner.profile_list = mod.PROFILE_LIST
      c.Spawner.options_from_form = mod.options_from_form
      c.KubeSpawner.pre_spawn_hook = mod.apply_profile_settings

    04-gpu-env: |
      # Base env for GPU-enabled images
      c.KubeSpawner.environment = {
          'NVIDIA_VISIBLE_DEVICES': 'all',
          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
      }

    95-per-profile-culler: |
      # Start internal per-profile culler (12h hard max for GPU profiles)
      import importlib.util, sys
      from jupyterhub.app import JupyterHub
      spec = importlib.util.spec_from_file_location("culler", "/etc/jupyterhub/extra/culler.py")
      cul = importlib.util.module_from_spec(spec); sys.modules["culler"] = cul; spec.loader.exec_module(cul)
      def _start(app: JupyterHub): app.io_loop.spawn_callback(cul.per_profile_cull, app)
      c.JupyterHub.post_hook = _start

singleuser:
  image:
    name: quay.io/jupyter/datascience-notebook
    tag: "2025-11-06"
    pullPolicy: IfNotPresent

  extraPodConfig:
    runtimeClassName: nvidia

  # ---------- STORAGE ----------
  storage:
    type: none
    extraVolumes:
      - name: fast-home
        emptyDir: {}
      - name: shared-rwx
        persistentVolumeClaim:
          claimName: jhub-shared-rwx
      - name: userdir-rwx
        persistentVolumeClaim:
          claimName: jhub-userdir-rwx
    extraVolumeMounts:
      - name: fast-home
        mountPath: /home/jovyan
      - name: shared-rwx
        mountPath: /home/jovyan/Shared
        readOnly: false
      - name: userdir-rwx
        mountPath: /home/jovyan/Persist
        readOnly: false
        subPathExpr: "users/$(JUPYTERHUB_USER)"

  uid: 1000
  fsGid: 100

  extraEnv:
    GRANT_SUDO: "yes"
    NOTEBOOK_ARGS: "--allow-root"
    JUPYTERHUB_SINGLEUSER_APP: "jupyter_server.serverapp.ServerApp"
    JUPYTERHUB_SINGLEUSER_ARGS: "--ServerApp.default_url=/lab/tree"
    XDG_CACHE_HOME: /home/jovyan/.cache
    PIP_CACHE_DIR: /home/jovyan/.cache/pip
    HF_HOME: /home/jovyan/.cache/huggingface
    TRANSFORMERS_CACHE: /home/jovyan/.cache/huggingface/transformers
    TORCH_HOME: /home/jovyan/.cache/torch
    NUMBA_CACHE_DIR: /home/jovyan/.cache/numba

  cloudMetadata:
    blockWithIptables: false

  lifecycleHooks:
    postStart:
      exec:
        command:
          - /bin/sh
          - -c
          - |
            set -eu
            echo "âš¡ Fast workspace (ephemeral):   /home/jovyan" > /home/jovyan/README.txt
            echo "ðŸ’¾ Persistent storage (NFS):     /home/jovyan/Persist" >> /home/jovyan/README.txt
            echo "ðŸ‘¥ Shared storage (NFS, RWX):    /home/jovyan/Shared"  >> /home/jovyan/README.txt
            [ -e /home/jovyan/Projects ] || mkdir -p /home/jovyan/Projects
            [ -e /home/jovyan/Data ] || mkdir -p /home/jovyan/Data
            [ -e /home/jovyan/Save ] || ln -s /home/jovyan/Persist /home/jovyan/Save
    preStop:
      exec:
        command:
          - /bin/sh
          - -c
          - |
            set -eu
            dst="/home/jovyan/Persist/last_session/$(date +%Y%m%d-%H%M%S)"
            mkdir -p "$dst" || true
            rsync -a --prune-empty-dirs \
              --include='*/' \
              --include='*.ipynb' --include='*.py' --include='*.md' \
              --exclude='.cache' --exclude='**/.git' --exclude='**/__pycache__' \
              /home/jovyan/ "$dst" || true

  cpu:
    limit: 2
    guarantee: 1
  memory:
    limit: 4G
    guarantee: 2G

scheduling:
  userScheduler:
    enabled: true
  podPriority:
    enabled: true
  userPlaceholder:
    enabled: false

prePuller:
  continuous:
    enabled: true

cull:
  enabled: true
  timeout: 3600
  every: 600
  maxAge: 0
  users: false
  adminUsers: true
  removeNamedServers: false
  concurrency: 20
