# JupyterHub Configuration for GPU Cluster

# Proxy configuration
proxy:
  secretToken: "GENERATE_WITH_openssl_rand_-hex_32"
  service:
    type: ClusterIP

# Ingress configuration for external access
ingress:
  enabled: true
  hosts:
    - jupyterhub.cps.unileoben.ac.at
  annotations:
    kubernetes.io/ingress.class: traefik
    cert-manager.io/cluster-issuer: letsencrypt-prod
  tls:
    - secretName: jupyterhub-tls
      hosts:
        - jupyterhub.cps.unileoben.ac.at

# Hub configuration
hub:
  config:
    JupyterHub:
      admin_access: true
      authenticator_class: oauthenticator.generic.GenericOAuthenticator
      # Enable named servers for power users
      allow_named_servers: true
      named_server_limit_per_user: 3
      template_vars:
        org:
          name: "Montanuniversit√§t Leoben"
          logo_url: "https://www.unileoben.ac.at/fileadmin/shares/allgemeine_datenbank/logos/1-mul-logo/2-mul-logo-smoke-quer.svg"
          url: "https://www.unileoben.ac.at"
    GenericOAuthenticator:
      client_id: "vUhzKqEF0UxPtZNM8aRbA1ncaehhIAIA2x9r83FI"
      client_secret: "EbAzlZLERPQzmF2EQByhihKuUqp36u138fYERPptymppmJbWhquI4sHu9vchqtnMRqbAVnZS6nOA6G0FescWa13MOLdlegQB3yyZSqe5V32NtYsnfDOndyZHiqiL2Bj6"
      oauth_callback_url: "https://jupyterhub.cps.unileoben.ac.at/hub/oauth_callback"
      authorize_url: "https://auth.cps.unileoben.ac.at/application/o/authorize/"
      token_url: "https://auth.cps.unileoben.ac.at/application/o/token/"
      userdata_url: "https://auth.cps.unileoben.ac.at/application/o/userinfo/"
      login_service: "CPS Authentik"
      username_claim: "preferred_username"
      scope:
        - "openid"
        - "profile"
        - "email"
        - "groups"
      claim_groups_key: "groups"
      manage_groups: true
      # Allow all authenticated users - access control handled by Authentik
      allow_all: true
      admin_groups:
        - "jupyter_admin"

  db:
    pvc:
      storageClassName: nfs-client
      storage: 10Gi
  
  extraVolumes:
    - name: custom-templates
      configMap:
        name: jupyterhub-custom-templates
  extraVolumeMounts:
    - name: custom-templates
      mountPath: /etc/jupyterhub/custom

  # Install OAuthenticator package and jupyterhub-fancy-profiles
  extraConfig:
    00-install-packages: |
      import subprocess
      import sys
      try:
        import oauthenticator
      except ImportError:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'oauthenticator'])
    
    01-custom-templates: |
      # Configure custom template path
      c.JupyterHub.template_paths = ['/etc/jupyterhub/custom']
      
      # Configure custom templates and info page
      import os
      from jupyterhub.handlers import BaseHandler
      from tornado import web
      
      class InfoHandler(BaseHandler):
          @web.authenticated
          async def get(self):
              user = await self.get_current_user()
              # Use JupyterHub's template environment instead of Tornado's direct render
              template_vars = {
                  'user': user,
                  'base_url': self.hub.base_url,
                  'org': getattr(self.settings.get('template_vars', {}), 'org', {}),
              }
              html = self.render_template("info.html", **template_vars)
              self.write(html)
      
      c.JupyterHub.extra_handlers = [
          (r"/info", InfoHandler),
      ]
      
    02-profiles: |
      # Dynamic profile configuration based on user groups
      # Adapted from Docker Swarm template for KubeSpawner
      def dynamic_profile_list(spawner):
          """
          Generate profile list dynamically based on user's group membership.
          Users in 'cpsHPCAccess' get full GPU access and custom image options.
          Other users get simple CPU-only profile.
          """
          import traceback
          try:
              user = spawner.user
              spawner.log.info(f"=== PROFILE LIST CALLED for user {user.name} ===")
              
              user_groups = set(group.name for group in user.groups)
              
              # Check if user has HPC access (equivalent to jhub-gpu group in Swarm config)
              has_hpc_access = 'cpsHPCAccess' in user_groups
              
              spawner.log.info(f"User {user.name} groups: {user_groups}, HPC access: {has_hpc_access}")
              
              if not has_hpc_access:
                  # Restricted profile for users without cpsHPCAccess group
                  profiles = [
                      {
                          'display_name': 'üíª Limited Access - Basic Computing',
                          'description': 'CPU-only notebook server (1 CPU core, 1.5 GB RAM). For full access to GPU resources and larger compute options, please contact your administrator to be added to the cpsHPCAccess group.',
                          'default': True,
                          'kubespawner_override': {
                              'cpu_limit': 1.0,
                              'cpu_guarantee': 0.5,
                              'mem_limit': '1.5G',
                              'mem_guarantee': '512M',
                              'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                          }
                      }
                  ]
                  spawner.log.info(f"Returning {len(profiles)} restricted profiles")
                  return profiles
              
              # Full access profiles for users in cpsHPCAccess group
              profiles = [
              # CPU Profiles - Different resource tiers
              {
                  'display_name': 'üíª DataScience - Small (1GB RAM, 2 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. Suitable for light data analysis.',
                  'default': True,
                  'kubespawner_override': {
                      'cpu_limit': 2.0,
                      'cpu_guarantee': 0.5,
                      'mem_limit': '1G',
                      'mem_guarantee': '256M',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              {
                  'display_name': 'ÔøΩ DataScience - Medium (4GB RAM, 4 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. Good for moderate workloads.',
                  'kubespawner_override': {
                      'cpu_limit': 4.0,
                      'cpu_guarantee': 1.0,
                      'mem_limit': '4G',
                      'mem_guarantee': '1G',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              {
                  'display_name': 'ÔøΩ DataScience - Large (8GB RAM, 8 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. For larger datasets.',
                  'kubespawner_override': {
                      'cpu_limit': 8.0,
                      'cpu_guarantee': 2.0,
                      'mem_limit': '8G',
                      'mem_guarantee': '2G',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              {
                  'display_name': 'üíª DataScience - XLarge (16GB RAM, 16 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. Maximum CPU resources.',
                  'kubespawner_override': {
                      'cpu_limit': 16.0,
                      'cpu_guarantee': 4.0,
                      'mem_limit': '16G',
                      'mem_guarantee': '4G',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              
              # GPU Profiles - A100 configurations
              {
                  'display_name': 'üöÄ Single A100 GPU - PyTorch (32GB RAM, 8 CPUs)',
                  'description': 'One NVIDIA A100 GPU with PyTorch. Perfect for deep learning and ML training.',
                  'kubespawner_override': {
                      'cpu_limit': 8.0,
                      'cpu_guarantee': 4.0,
                      'mem_limit': '32G',
                      'mem_guarantee': '16G',
                      'extra_resource_limits': {'nvidia.com/gpu': '1'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '1'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/pytorch-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              },
              {
                  'display_name': 'üöÄ Single A100 GPU - TensorFlow (32GB RAM, 8 CPUs)',
                  'description': 'One NVIDIA A100 GPU with TensorFlow. Optimized for TensorFlow workloads.',
                  'kubespawner_override': {
                      'cpu_limit': 8.0,
                      'cpu_guarantee': 4.0,
                      'mem_limit': '32G',
                      'mem_guarantee': '16G',
                      'extra_resource_limits': {'nvidia.com/gpu': '1'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '1'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/tensorflow-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              },
              {
                  'display_name': 'üî• Dual A100 GPUs - PyTorch (64GB RAM, 16 CPUs)',
                  'description': 'Two NVIDIA A100 GPUs with PyTorch. Maximum performance for large-scale training.',
                  'kubespawner_override': {
                      'cpu_limit': 16.0,
                      'cpu_guarantee': 8.0,
                      'mem_limit': '64G',
                      'mem_guarantee': '32G',
                      'extra_resource_limits': {'nvidia.com/gpu': '2'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '2'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/pytorch-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              },
              {
                  'display_name': 'üî• Dual A100 GPUs - TensorFlow (64GB RAM, 16 CPUs)',
                  'description': 'Two NVIDIA A100 GPUs with TensorFlow. Maximum performance for TensorFlow workloads.',
                  'kubespawner_override': {
                      'cpu_limit': 16.0,
                      'cpu_guarantee': 8.0,
                      'mem_limit': '64G',
                      'mem_guarantee': '32G',
                      'extra_resource_limits': {'nvidia.com/gpu': '2'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '2'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/tensorflow-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              }
              
              # NOTE: Custom image profile with profile_options temporarily disabled
              # This complex profile might be causing frontend rendering issues
              # Will re-enable after testing simpler profiles work
              # {
              #     'display_name': '‚öôÔ∏è Custom Docker Image',
              #     'description': 'Specify your own container image...',
              #     'profile_options': { ... }
              # }
              ]
              spawner.log.info(f"Returning {len(profiles)} HPC profiles")
              return profiles
          
          except Exception as e:
              spawner.log.error(f"ERROR in dynamic_profile_list: {e}")
              spawner.log.error(traceback.format_exc())
              # Return a safe default
              return [{
                  'display_name': 'Default Environment',
                  'description': 'An error occurred loading profiles. Using default configuration.',
                  'default': True
              }]
      
      # Set the dynamic profile list callable on KubeSpawner
      c.KubeSpawner.profile_list = dynamic_profile_list
        
    gpu-config: |
      # Make GPUs available to users
      c.KubeSpawner.environment = {
          'NVIDIA_VISIBLE_DEVICES': 'all',
          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
      }

# Singleuser notebook configuration
singleuser:
  # Default image with CUDA support
  image:
    name: quay.io/jupyter/tensorflow-notebook
    tag: "2025-11-06"
    pullPolicy: IfNotPresent
  
  # Storage for user notebooks
  storage:
    capacity: 10Gi
    dynamic:
      storageClass: nfs-client
    homeMountPath: /home/jovyan
  
  # Default resources (no GPU)
  cpu:
    limit: 2
    guarantee: 1
  memory:
    limit: 4G
    guarantee: 2G
  
  # Profile list now configured via jupyterhub-fancy-profiles in extraConfig

  # Allow users to sudo (for package installation)
  uid: 1000
  fsGid: 100
  extraEnv:
    GRANT_SUDO: "yes"
    NOTEBOOK_ARGS: "--allow-root"

# Scheduling
scheduling:
  userScheduler:
    enabled: true
  podPriority:
    enabled: true
  userPlaceholder:
    enabled: false

# Culling (shut down idle notebooks)
cull:
  enabled: true
  timeout: 3600  # 1 hour
  every: 600     # Check every 10 minutes
  maxAge: 0      # Don't cull based on age
