# JupyterHub Configuration for GPU Cluster

# Proxy configuration
proxy:
  secretToken: "GENERATE_WITH_openssl_rand_-hex_32"
  service:
    type: ClusterIP

# Ingress configuration for external access
ingress:
  enabled: true
  hosts:
    - jupyterhub.cps.unileoben.ac.at
  annotations:
    kubernetes.io/ingress.class: traefik
    cert-manager.io/cluster-issuer: letsencrypt-prod
  tls:
    - secretName: jupyterhub-tls
      hosts:
        - jupyterhub.cps.unileoben.ac.at

# Hub configuration
hub:
  config:
    JupyterHub:
      admin_access: true
      authenticator_class: oauthenticator.generic.GenericOAuthenticator
      # Enable named servers for power users
      allow_named_servers: true
      named_server_limit_per_user: 3
      template_vars:
        org:
          name: "MontanuniversitÃ¤t Leoben"
          logo_url: "https://www.unileoben.ac.at/fileadmin/shares/allgemeine_datenbank/logos/1-mul-logo/2-mul-logo-smoke-quer.svg"
          url: "https://www.unileoben.ac.at"
    GenericOAuthenticator:
      client_id: "vUhzKqEF0UxPtZNM8aRbA1ncaehhIAIA2x9r83FI"
      client_secret: "EbAzlZLERPQzmF2EQByhihKuUqp36u138fYERPptymppmJbWhquI4sHu9vchqtnMRqbAVnZS6nOA6G0FescWa13MOLdlegQB3yyZSqe5V32NtYsnfDOndyZHiqiL2Bj6"
      oauth_callback_url: "https://jupyterhub.cps.unileoben.ac.at/hub/oauth_callback"
      authorize_url: "https://auth.cps.unileoben.ac.at/application/o/authorize/"
      token_url: "https://auth.cps.unileoben.ac.at/application/o/token/"
      userdata_url: "https://auth.cps.unileoben.ac.at/application/o/userinfo/"
      login_service: "CPS Authentik"
      username_claim: "preferred_username"
      scope:
        - "openid"
        - "profile"
        - "email"
        - "groups"
      claim_groups_key: "groups"
      manage_groups: true
      # Allow all authenticated users - access control handled by Authentik
      allow_all: true
      admin_groups:
        - "jupyter_admin"

  db:
    pvc:
      storageClassName: nfs-client
      storage: 10Gi
  
  extraVolumes:
    - name: custom-templates
      configMap:
        name: jupyterhub-custom-templates
  extraVolumeMounts:
    - name: custom-templates
      mountPath: /etc/jupyterhub/custom

  # Install OAuthenticator package and jupyterhub-fancy-profiles
  extraConfig:
    00-install-packages: |
      import subprocess
      import sys
      try:
        import oauthenticator
      except ImportError:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'oauthenticator'])
    
    01-custom-templates: |
      # Configure custom template path
      c.JupyterHub.template_paths = ['/etc/jupyterhub/custom']
      
      # Configure custom templates and info page
      import os
      from jupyterhub.handlers import BaseHandler
      from tornado import web
      
      class InfoHandler(BaseHandler):
          @web.authenticated
          async def get(self):
              user = await self.get_current_user()
              # Use JupyterHub's template environment instead of Tornado's direct render
              template_vars = {
                  'user': user,
                  'base_url': self.hub.base_url,
                  'org': getattr(self.settings.get('template_vars', {}), 'org', {}),
              }
              html = self.render_template("info.html", **template_vars)
              self.write(html)
      
      c.JupyterHub.extra_handlers = [
          (r"/info", InfoHandler),
      ]
      
    02-profiles: |
      # GPU profiles requiring access control
      GPU_PROFILE_SLUGS = {'gpu-pytorch-single', 'gpu-tensorflow-single', 'gpu-pytorch-dual', 'gpu-tensorflow-dual'}
      ALLOWED_GPU_GROUPS = {'cpsHPCAccess', 'jupyter_admin'}
      
      # Profile list - base profiles available to all
      BASE_PROFILE_LIST = [
          # CPU Profiles - Available to all users
          {
              'display_name': 'ðŸ’» DataScience - Small (1GB RAM, 2 CPUs)',
              'description': 'CPU-only with pandas, scikit-learn, matplotlib. Suitable for light data analysis.',
              'slug': 'cpu-small',
              'default': True,
              'kubespawner_override': {
                  'cpu_limit': 2.0,
                  'cpu_guarantee': 0.5,
                  'mem_limit': '1G',
                  'mem_guarantee': '256M',
                  'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
              }
          },
          {
              'display_name': 'ðŸ’» DataScience - Medium (4GB RAM, 4 CPUs)',
              'description': 'CPU-only with pandas, scikit-learn, matplotlib. Good for moderate workloads.',
              'slug': 'cpu-medium',
              'kubespawner_override': {
                  'cpu_limit': 4.0,
                  'cpu_guarantee': 1.0,
                  'mem_limit': '4G',
                  'mem_guarantee': '1G',
                  'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
              }
          },
          {
              'display_name': 'ðŸ’» DataScience - Large (8GB RAM, 8 CPUs)',
              'description': 'CPU-only with pandas, scikit-learn, matplotlib. For larger datasets.',
              'slug': 'cpu-large',
              'kubespawner_override': {
                  'cpu_limit': 8.0,
                  'cpu_guarantee': 2.0,
                  'mem_limit': '8G',
                  'mem_guarantee': '2G',
                  'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
              }
          },
          {
              'display_name': 'ðŸ’» DataScience - XLarge (16GB RAM, 16 CPUs)',
              'description': 'CPU-only with pandas, scikit-learn, matplotlib. Maximum CPU resources.',
              'slug': 'cpu-xlarge',
              'kubespawner_override': {
                  'cpu_limit': 16.0,
                  'cpu_guarantee': 4.0,
                  'mem_limit': '16G',
                  'mem_guarantee': '4G',
                  'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
              }
          },
      ]
      
      # GPU profiles - only for authorized users
      GPU_PROFILE_LIST = [
          {
              'display_name': 'ðŸš€ Single A100 GPU - PyTorch (32GB RAM, 8 CPUs)',
              'description': 'One NVIDIA A100 GPU with PyTorch. Perfect for deep learning and ML training.',
              'slug': 'gpu-pytorch-single',
              'kubespawner_override': {
                  'cpu_limit': 8.0,
                  'cpu_guarantee': 4.0,
                  'mem_limit': '32G',
                  'mem_guarantee': '16G',
                  'extra_resource_limits': {'nvidia.com/gpu': '1'},
                  'extra_resource_guarantees': {'nvidia.com/gpu': '1'},
                  'node_selector': {'accelerator': 'nvidia'},
                  'image': 'quay.io/jupyter/pytorch-notebook:2025-11-06',
                  'environment': {
                      'NVIDIA_VISIBLE_DEVICES': 'all',
                      'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                  }
              }
          },
          {
              'display_name': 'ðŸš€ Single A100 GPU - TensorFlow (32GB RAM, 8 CPUs)',
              'description': 'One NVIDIA A100 GPU with TensorFlow. Optimized for TensorFlow workloads.',
              'slug': 'gpu-tensorflow-single',
              'kubespawner_override': {
                  'cpu_limit': 8.0,
                  'cpu_guarantee': 4.0,
                  'mem_limit': '32G',
                  'mem_guarantee': '16G',
                  'extra_resource_limits': {'nvidia.com/gpu': '1'},
                  'extra_resource_guarantees': {'nvidia.com/gpu': '1'},
                  'node_selector': {'accelerator': 'nvidia'},
                  'image': 'quay.io/jupyter/tensorflow-notebook:2025-11-06',
                  'environment': {
                      'NVIDIA_VISIBLE_DEVICES': 'all',
                      'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                  }
              }
          },
          {
              'display_name': 'ðŸ”¥ Dual A100 GPUs - PyTorch (64GB RAM, 16 CPUs)',
              'description': 'Two NVIDIA A100 GPUs with PyTorch. Maximum performance for large-scale training.',
              'slug': 'gpu-pytorch-dual',
              'kubespawner_override': {
                  'cpu_limit': 16.0,
                  'cpu_guarantee': 8.0,
                  'mem_limit': '64G',
                  'mem_guarantee': '32G',
                  'extra_resource_limits': {'nvidia.com/gpu': '2'},
                  'extra_resource_guarantees': {'nvidia.com/gpu': '2'},
                  'node_selector': {'accelerator': 'nvidia'},
                  'image': 'quay.io/jupyter/pytorch-notebook:2025-11-06',
                  'environment': {
                      'NVIDIA_VISIBLE_DEVICES': 'all',
                      'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                  }
              }
          },
          {
              'display_name': 'ðŸ”¥ Dual A100 GPUs - TensorFlow (64GB RAM, 16 CPUs)',
              'description': 'Two NVIDIA A100 GPUs with TensorFlow. Maximum performance for TensorFlow workloads.',
              'slug': 'gpu-tensorflow-dual',
              'kubespawner_override': {
                  'cpu_limit': 16.0,
                  'cpu_guarantee': 8.0,
                  'mem_limit': '64G',
                  'mem_guarantee': '32G',
                  'extra_resource_limits': {'nvidia.com/gpu': '2'},
                  'extra_resource_guarantees': {'nvidia.com/gpu': '2'},
                  'node_selector': {'accelerator': 'nvidia'},
                  'image': 'quay.io/jupyter/tensorflow-notebook:2025-11-06',
                  'environment': {
                      'NVIDIA_VISIBLE_DEVICES': 'all',
                      'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                  }
              }
          }
      ]
      
      # Dynamic profile list based on user groups
      def get_profile_list(spawner):
          """Return profile list based on user's GPU access"""
          group_names = {group.name for group in spawner.user.groups}
          has_gpu_access = bool(group_names & ALLOWED_GPU_GROUPS)
          
          spawner.log.info(f"User {spawner.user.name} groups: {group_names}, GPU access: {has_gpu_access}")
          
          if has_gpu_access:
              profiles = BASE_PROFILE_LIST + GPU_PROFILE_LIST
              spawner.log.info(f"User {spawner.user.name} granted access to {len(profiles)} profiles (including GPU)")
          else:
              profiles = BASE_PROFILE_LIST
              spawner.log.info(f"User {spawner.user.name} limited to {len(profiles)} CPU-only profiles")
          
          return profiles
      
      c.KubeSpawner.profile_list = get_profile_list
      
      # Pre-spawn hook to enforce group-based access control (defense in depth)
      async def check_profile_access(spawner):
          """
          Enforce group-based access control for GPU profiles.
          This runs before spawning and blocks unauthorized access to GPU profiles.
          """
          # Get selected profile
          profile_slug = spawner.user_options.get('profile', '')
          
          # Check if it's a GPU profile
          if profile_slug in GPU_PROFILE_SLUGS:
              # Get user's groups
              group_names = {group.name for group in spawner.user.groups}
              
              # Check if user has GPU access
              if not (group_names & ALLOWED_GPU_GROUPS):
                  spawner.log.warning(f"User {spawner.user.name} attempted to access GPU profile {profile_slug} without permission (groups: {group_names})")
                  raise Exception(f"Access denied: GPU profiles require membership in one of these groups: {', '.join(ALLOWED_GPU_GROUPS)}")
              else:
                  spawner.log.info(f"User {spawner.user.name} authorized for GPU profile {profile_slug} (groups: {group_names & ALLOWED_GPU_GROUPS})")
          
          spawner.log.info(f"User {spawner.user.name} spawning with profile: {profile_slug}")
      
      c.KubeSpawner.pre_spawn_hook = check_profile_access
        
    gpu-config: |
      # Make GPUs available to users
      c.KubeSpawner.environment = {
          'NVIDIA_VISIBLE_DEVICES': 'all',
          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
      }

# Singleuser notebook configuration
singleuser:
  # Default image with CUDA support
  image:
    name: quay.io/jupyter/tensorflow-notebook
    tag: "2025-11-06"
    pullPolicy: IfNotPresent
  
  # Storage for user notebooks
  storage:
    capacity: 10Gi
    dynamic:
      storageClass: nfs-client
    homeMountPath: /home/jovyan
  
  # Default resources (no GPU)
  cpu:
    limit: 2
    guarantee: 1
  memory:
    limit: 4G
    guarantee: 2G
  
  # Profile list now configured via jupyterhub-fancy-profiles in extraConfig

  # Allow users to sudo (for package installation)
  uid: 1000
  fsGid: 100
  extraEnv:
    GRANT_SUDO: "yes"
    NOTEBOOK_ARGS: "--allow-root"

# Scheduling
scheduling:
  userScheduler:
    enabled: true
  podPriority:
    enabled: true
  userPlaceholder:
    enabled: false

# Culling (shut down idle notebooks)
cull:
  enabled: true
  timeout: 3600  # 1 hour
  every: 600     # Check every 10 minutes
  maxAge: 0      # Don't cull based on age
