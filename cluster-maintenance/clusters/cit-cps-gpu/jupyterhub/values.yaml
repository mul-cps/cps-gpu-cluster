# JupyterHub Configuration for GPU Cluster

# Proxy configuration
proxy:
  secretToken: "GENERATE_WITH_openssl_rand_-hex_32"
  service:
    type: ClusterIP

# Ingress configuration for external access
ingress:
  enabled: true
  hosts:
    - jupyterhub.cps.unileoben.ac.at
  annotations:
    kubernetes.io/ingress.class: traefik
    cert-manager.io/cluster-issuer: letsencrypt-prod
  tls:
    - secretName: jupyterhub-tls
      hosts:
        - jupyterhub.cps.unileoben.ac.at

# Hub configuration
hub:
  config:
    JupyterHub:
      admin_access: true
      authenticator_class: oauthenticator.generic.GenericOAuthenticator
      # Enable named servers for power users
      allow_named_servers: true
      named_server_limit_per_user: 3
      template_vars:
        org:
          name: "MontanuniversitÃ¤t Leoben"
          logo_url: "https://www.unileoben.ac.at/fileadmin/shares/allgemeine_datenbank/logos/1-mul-logo/2-mul-logo-smoke-quer.svg"
          url: "https://www.unileoben.ac.at"
    GenericOAuthenticator:
      client_id: "vUhzKqEF0UxPtZNM8aRbA1ncaehhIAIA2x9r83FI"
      client_secret: "EbAzlZLERPQzmF2EQByhihKuUqp36u138fYERPptymppmJbWhquI4sHu9vchqtnMRqbAVnZS6nOA6G0FescWa13MOLdlegQB3yyZSqe5V32NtYsnfDOndyZHiqiL2Bj6"
      oauth_callback_url: "https://jupyterhub.cps.unileoben.ac.at/hub/oauth_callback"
      authorize_url: "https://auth.cps.unileoben.ac.at/application/o/authorize/"
      token_url: "https://auth.cps.unileoben.ac.at/application/o/token/"
      userdata_url: "https://auth.cps.unileoben.ac.at/application/o/userinfo/"
      login_service: "CPS Authentik"
      username_claim: "preferred_username"
      scope:
        - "openid"
        - "profile"
        - "email"
        - "groups"
      claim_groups_key: "groups"
      manage_groups: true
      # Allow all authenticated users - access control handled by Authentik
      allow_all: true
      admin_groups:
        - "jupyter_admin"

  db:
    pvc:
      storageClassName: nfs-client
      storage: 10Gi
  
  extraVolumes:
    - name: custom-templates
      configMap:
        name: jupyterhub-custom-templates
  extraVolumeMounts:
    - name: custom-templates
      mountPath: /etc/jupyterhub/custom

  # Install OAuthenticator package and jupyterhub-fancy-profiles
  extraConfig:
    00-install-packages: |
      import subprocess
      import sys
      try:
        import oauthenticator
      except ImportError:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'oauthenticator'])
    
    01-custom-templates: |
      # Configure custom template path
      c.JupyterHub.template_paths = ['/etc/jupyterhub/custom']
      
      # Configure custom templates and info page
      import os
      from jupyterhub.handlers import BaseHandler
      from tornado import web
      
      class InfoHandler(BaseHandler):
          @web.authenticated
          async def get(self):
              user = await self.get_current_user()
              # Use JupyterHub's template environment instead of Tornado's direct render
              template_vars = {
                  'user': user,
                  'base_url': self.hub.base_url,
                  'org': getattr(self.settings.get('template_vars', {}), 'org', {}),
              }
              html = self.render_template("info.html", **template_vars)
              self.write(html)
      
      c.JupyterHub.extra_handlers = [
          (r"/info", InfoHandler),
      ]
      
    02-profiles: |
      # Define all available profiles
      # GPU profiles will be filtered based on group membership
      ALL_PROFILES = [
          # CPU Profiles - Available to all users
          {
              'display_name': 'ðŸ’» DataScience - Small (1GB RAM, 2 CPUs)',
              'description': 'CPU-only with pandas, scikit-learn, matplotlib. Suitable for light data analysis.',
              'slug': 'cpu-small',
              'default': True,
                  'kubespawner_override': {
                      'cpu_limit': 2.0,
                      'cpu_guarantee': 0.5,
                      'mem_limit': '1G',
                      'mem_guarantee': '256M',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              {
                  'display_name': 'ðŸ’» DataScience - Medium (4GB RAM, 4 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. Good for moderate workloads.',
                  'slug': 'cpu-medium',
                  'kubespawner_override': {
                      'cpu_limit': 4.0,
                      'cpu_guarantee': 1.0,
                      'mem_limit': '4G',
                      'mem_guarantee': '1G',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              {
                  'display_name': 'ðŸ’» DataScience - Large (8GB RAM, 8 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. For larger datasets.',
                  'slug': 'cpu-large',
                  'kubespawner_override': {
                      'cpu_limit': 8.0,
                      'cpu_guarantee': 2.0,
                      'mem_limit': '8G',
                      'mem_guarantee': '2G',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              {
                  'display_name': 'ðŸ’» DataScience - XLarge (16GB RAM, 16 CPUs)',
                  'description': 'CPU-only with pandas, scikit-learn, matplotlib. Maximum CPU resources.',
                  'slug': 'cpu-xlarge',
                  'kubespawner_override': {
                      'cpu_limit': 16.0,
                      'cpu_guarantee': 4.0,
                      'mem_limit': '16G',
                      'mem_guarantee': '4G',
                      'image': 'quay.io/jupyter/datascience-notebook:2025-11-06'
                  }
              },
              
              # GPU Profiles - Require cpsHPCAccess group membership
              {
                  'display_name': 'ðŸš€ Single A100 GPU - PyTorch (32GB RAM, 8 CPUs)',
                  'description': 'One NVIDIA A100 GPU with PyTorch. Perfect for deep learning and ML training.',
                  'slug': 'gpu-pytorch-single',
                  'allowed_groups': ['cpsHPCAccess', 'jupyter_admin'],
                  'kubespawner_override': {
                      'cpu_limit': 8.0,
                      'cpu_guarantee': 4.0,
                      'mem_limit': '32G',
                      'mem_guarantee': '16G',
                      'extra_resource_limits': {'nvidia.com/gpu': '1'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '1'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/pytorch-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              },
              {
                  'display_name': 'ðŸš€ Single A100 GPU - TensorFlow (32GB RAM, 8 CPUs)',
                  'description': 'One NVIDIA A100 GPU with TensorFlow. Optimized for TensorFlow workloads.',
                  'slug': 'gpu-tensorflow-single',
                  'allowed_groups': ['cpsHPCAccess', 'jupyter_admin'],
                  'kubespawner_override': {
                      'cpu_limit': 8.0,
                      'cpu_guarantee': 4.0,
                      'mem_limit': '32G',
                      'mem_guarantee': '16G',
                      'extra_resource_limits': {'nvidia.com/gpu': '1'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '1'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/tensorflow-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              },
              {
                  'display_name': 'ðŸ”¥ Dual A100 GPUs - PyTorch (64GB RAM, 16 CPUs)',
                  'description': 'Two NVIDIA A100 GPUs with PyTorch. Maximum performance for large-scale training.',
                  'slug': 'gpu-pytorch-dual',
                  'allowed_groups': ['cpsHPCAccess', 'jupyter_admin'],
                  'kubespawner_override': {
                      'cpu_limit': 16.0,
                      'cpu_guarantee': 8.0,
                      'mem_limit': '64G',
                      'mem_guarantee': '32G',
                      'extra_resource_limits': {'nvidia.com/gpu': '2'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '2'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/pytorch-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              },
              {
                  'display_name': 'ðŸ”¥ Dual A100 GPUs - TensorFlow (64GB RAM, 16 CPUs)',
                  'description': 'Two NVIDIA A100 GPUs with TensorFlow. Maximum performance for TensorFlow workloads.',
                  'slug': 'gpu-tensorflow-dual',
                  'allowed_groups': ['cpsHPCAccess', 'jupyter_admin'],
                  'kubespawner_override': {
                      'cpu_limit': 16.0,
                      'cpu_guarantee': 8.0,
                      'mem_limit': '64G',
                      'mem_guarantee': '32G',
                      'extra_resource_limits': {'nvidia.com/gpu': '2'},
                      'extra_resource_guarantees': {'nvidia.com/gpu': '2'},
                      'node_selector': {'accelerator': 'nvidia'},
                      'image': 'quay.io/jupyter/tensorflow-notebook:2025-11-06',
                      'environment': {
                          'NVIDIA_VISIBLE_DEVICES': 'all',
                          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
                      }
                  }
              }
      ]
      
      # Custom options form to filter profiles based on user groups
      async def custom_options_form(spawner):
          """
          Dynamically filter profile list based on user's group membership.
          Profiles with 'allowed_groups' are only shown to users in those groups.
          Profiles without 'allowed_groups' are shown to everyone.
          """
          # Get user's group membership from JupyterHub (populated by OAuth via manage_groups)
          group_names = {group.name for group in spawner.user.groups}
          
          spawner.log.info(f"User {spawner.user.name} groups: {group_names}")
          
          # Filter profiles based on group membership
          allowed_profiles = []
          for profile in ALL_PROFILES:
              # If profile has no allowed_groups restriction, show to everyone
              if 'allowed_groups' not in profile:
                  allowed_profiles.append(profile)
                  spawner.log.debug(f"Profile {profile['slug']} available to all users")
              else:
                  # Check if user is in any of the allowed groups
                  profile_allowed_groups = set(profile['allowed_groups'])
                  if group_names & profile_allowed_groups:  # Set intersection
                      allowed_profiles.append(profile)
                      spawner.log.info(f"Profile {profile['slug']} granted to {spawner.user.name} (groups: {group_names & profile_allowed_groups})")
                  else:
                      spawner.log.debug(f"Profile {profile['slug']} restricted from {spawner.user.name} (requires: {profile_allowed_groups})")
          
          # Set the filtered profile list
          spawner.profile_list = allowed_profiles
          
          spawner.log.info(f"User {spawner.user.name} has access to {len(allowed_profiles)} profiles")
          
          # Use KubeSpawner's default options form rendering
          return spawner._options_form_default()
      
      # Assign the custom options form
      c.KubeSpawner.options_form = custom_options_form
        
    gpu-config: |
      # Make GPUs available to users
      c.KubeSpawner.environment = {
          'NVIDIA_VISIBLE_DEVICES': 'all',
          'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility'
      }

# Singleuser notebook configuration
singleuser:
  # Default image with CUDA support
  image:
    name: quay.io/jupyter/tensorflow-notebook
    tag: "2025-11-06"
    pullPolicy: IfNotPresent
  
  # Storage for user notebooks
  storage:
    capacity: 10Gi
    dynamic:
      storageClass: nfs-client
    homeMountPath: /home/jovyan
  
  # Default resources (no GPU)
  cpu:
    limit: 2
    guarantee: 1
  memory:
    limit: 4G
    guarantee: 2G
  
  # Profile list now configured via jupyterhub-fancy-profiles in extraConfig

  # Allow users to sudo (for package installation)
  uid: 1000
  fsGid: 100
  extraEnv:
    GRANT_SUDO: "yes"
    NOTEBOOK_ARGS: "--allow-root"

# Scheduling
scheduling:
  userScheduler:
    enabled: true
  podPriority:
    enabled: true
  userPlaceholder:
    enabled: false

# Culling (shut down idle notebooks)
cull:
  enabled: true
  timeout: 3600  # 1 hour
  every: 600     # Check every 10 minutes
  maxAge: 0      # Don't cull based on age
